{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. sklearn 패키지를 사용해 로지스틱 회귀모형으로 데이터를 분석해 주세요 \n",
    "2. 성능지표를 계산하고 이에 대해 해석해 주세요 \n",
    "   - sklearn : mean accuracy, f1 score 등 다양한 성능지표 계산 \n",
    "   - confusion matrix : tp, fp, fn, tn 값을 통해 성능지표 계산  \n",
    "3. 로지스틱 회귀분석은 cutoff 설정 값에 따라 classification의 성능이 달라집니다.      \n",
    "   해당 데이터셋에 걸맞는 cutoff value를 찾아보고, 이를 기반으로 예측을 진행해 성능을 평가해 주세요.\n",
    "4. **해석을 상세하게 달아주세요 !**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "출처 : https://www.kaggle.com/mlg-ulb/creditcardfraud\n",
    "\n",
    "\n",
    "* V1 ~ V28 : 비식별화 된 개인정보 \n",
    "* **Class** : Target 변수  \n",
    "  - 1 : fraudulent transactions (사기)\n",
    "  - 0 : otherwise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    본격적인 분석에 앞서 기본적인 데이터에 대한 정보와 분석 툴들을 설정한다. 주어진 데이터셋은 비식별화 된 개인정보를 독립변수로, class를 반응변수로 둔 데이터로 반응변수의 값이 0과 1로만 이루어져 있으므로 logistic regression을 진행해야한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv(\"assignment3_creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.848212</td>\n",
       "      <td>2.384900</td>\n",
       "      <td>0.379573</td>\n",
       "      <td>1.048381</td>\n",
       "      <td>-0.845070</td>\n",
       "      <td>2.537837</td>\n",
       "      <td>-4.542983</td>\n",
       "      <td>-10.201458</td>\n",
       "      <td>-1.504967</td>\n",
       "      <td>-2.234167</td>\n",
       "      <td>...</td>\n",
       "      <td>2.585817</td>\n",
       "      <td>-5.291690</td>\n",
       "      <td>0.859364</td>\n",
       "      <td>0.423231</td>\n",
       "      <td>-0.506985</td>\n",
       "      <td>1.020052</td>\n",
       "      <td>-0.627751</td>\n",
       "      <td>-0.017753</td>\n",
       "      <td>0.280982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.071805</td>\n",
       "      <td>-0.477943</td>\n",
       "      <td>-1.444444</td>\n",
       "      <td>-0.548657</td>\n",
       "      <td>0.010036</td>\n",
       "      <td>-0.582242</td>\n",
       "      <td>-0.042878</td>\n",
       "      <td>-0.247160</td>\n",
       "      <td>1.171923</td>\n",
       "      <td>-0.342382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.077306</td>\n",
       "      <td>0.042858</td>\n",
       "      <td>0.390125</td>\n",
       "      <td>0.041569</td>\n",
       "      <td>0.598427</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>0.979686</td>\n",
       "      <td>-0.093244</td>\n",
       "      <td>-0.065615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.985294</td>\n",
       "      <td>-2.747472</td>\n",
       "      <td>1.194068</td>\n",
       "      <td>-0.003036</td>\n",
       "      <td>-1.151041</td>\n",
       "      <td>-0.263559</td>\n",
       "      <td>0.553500</td>\n",
       "      <td>0.635600</td>\n",
       "      <td>0.438545</td>\n",
       "      <td>-1.806488</td>\n",
       "      <td>...</td>\n",
       "      <td>1.345776</td>\n",
       "      <td>0.373760</td>\n",
       "      <td>-0.385777</td>\n",
       "      <td>1.197596</td>\n",
       "      <td>0.407229</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.762362</td>\n",
       "      <td>-0.299024</td>\n",
       "      <td>-0.303929</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.479452</td>\n",
       "      <td>1.542874</td>\n",
       "      <td>0.290895</td>\n",
       "      <td>0.838142</td>\n",
       "      <td>-0.529290</td>\n",
       "      <td>-0.717661</td>\n",
       "      <td>0.484516</td>\n",
       "      <td>0.545092</td>\n",
       "      <td>-0.780767</td>\n",
       "      <td>0.324804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038397</td>\n",
       "      <td>0.116771</td>\n",
       "      <td>0.405560</td>\n",
       "      <td>-0.116453</td>\n",
       "      <td>0.541275</td>\n",
       "      <td>-0.216665</td>\n",
       "      <td>-0.415578</td>\n",
       "      <td>0.027126</td>\n",
       "      <td>-0.150347</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.281976</td>\n",
       "      <td>-0.309699</td>\n",
       "      <td>-2.162299</td>\n",
       "      <td>-0.851514</td>\n",
       "      <td>0.106167</td>\n",
       "      <td>-1.483888</td>\n",
       "      <td>1.930994</td>\n",
       "      <td>-0.843049</td>\n",
       "      <td>-1.249272</td>\n",
       "      <td>1.079608</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.875516</td>\n",
       "      <td>-0.004199</td>\n",
       "      <td>1.015108</td>\n",
       "      <td>-0.026748</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>-1.468822</td>\n",
       "      <td>0.751700</td>\n",
       "      <td>0.496732</td>\n",
       "      <td>0.331001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -1.848212  2.384900  0.379573  1.048381 -0.845070  2.537837 -4.542983   \n",
       "1  2.071805 -0.477943 -1.444444 -0.548657  0.010036 -0.582242 -0.042878   \n",
       "2 -2.985294 -2.747472  1.194068 -0.003036 -1.151041 -0.263559  0.553500   \n",
       "3 -1.479452  1.542874  0.290895  0.838142 -0.529290 -0.717661  0.484516   \n",
       "4 -0.281976 -0.309699 -2.162299 -0.851514  0.106167 -1.483888  1.930994   \n",
       "\n",
       "          V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0 -10.201458 -1.504967 -2.234167  ...  2.585817 -5.291690  0.859364  0.423231   \n",
       "1  -0.247160  1.171923 -0.342382  ... -0.077306  0.042858  0.390125  0.041569   \n",
       "2   0.635600  0.438545 -1.806488  ...  1.345776  0.373760 -0.385777  1.197596   \n",
       "3   0.545092 -0.780767  0.324804  ...  0.038397  0.116771  0.405560 -0.116453   \n",
       "4  -0.843049 -1.249272  1.079608  ... -0.875516 -0.004199  1.015108 -0.026748   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0 -0.506985  1.020052 -0.627751 -0.017753  0.280982      0  \n",
       "1  0.598427  0.098803  0.979686 -0.093244 -0.065615      0  \n",
       "2  0.407229  0.008013  0.762362 -0.299024 -0.303929      0  \n",
       "3  0.541275 -0.216665 -0.415578  0.027126 -0.150347      0  \n",
       "4  0.077115 -1.468822  0.751700  0.496732  0.331001      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "      <td>28678.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.015438</td>\n",
       "      <td>0.053653</td>\n",
       "      <td>-0.046031</td>\n",
       "      <td>0.037348</td>\n",
       "      <td>-0.033724</td>\n",
       "      <td>-0.003299</td>\n",
       "      <td>-0.051054</td>\n",
       "      <td>0.006064</td>\n",
       "      <td>-0.018530</td>\n",
       "      <td>-0.041149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.010289</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>-0.004800</td>\n",
       "      <td>-0.000897</td>\n",
       "      <td>-0.001989</td>\n",
       "      <td>-0.000765</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.001535</td>\n",
       "      <td>0.008578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.031529</td>\n",
       "      <td>1.616186</td>\n",
       "      <td>1.758169</td>\n",
       "      <td>1.482109</td>\n",
       "      <td>1.486998</td>\n",
       "      <td>1.339259</td>\n",
       "      <td>1.454827</td>\n",
       "      <td>1.364342</td>\n",
       "      <td>1.134065</td>\n",
       "      <td>1.252593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.720307</td>\n",
       "      <td>0.847152</td>\n",
       "      <td>0.739469</td>\n",
       "      <td>0.593663</td>\n",
       "      <td>0.603349</td>\n",
       "      <td>0.517968</td>\n",
       "      <td>0.483852</td>\n",
       "      <td>0.397075</td>\n",
       "      <td>0.296736</td>\n",
       "      <td>0.092221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-30.552380</td>\n",
       "      <td>-42.172688</td>\n",
       "      <td>-31.103685</td>\n",
       "      <td>-5.560118</td>\n",
       "      <td>-42.147898</td>\n",
       "      <td>-21.929312</td>\n",
       "      <td>-41.506796</td>\n",
       "      <td>-39.267378</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-24.403185</td>\n",
       "      <td>...</td>\n",
       "      <td>-21.387122</td>\n",
       "      <td>-21.453736</td>\n",
       "      <td>-8.887017</td>\n",
       "      <td>-36.666000</td>\n",
       "      <td>-2.718024</td>\n",
       "      <td>-6.712624</td>\n",
       "      <td>-2.241620</td>\n",
       "      <td>-7.418878</td>\n",
       "      <td>-9.617915</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.916927</td>\n",
       "      <td>-0.575381</td>\n",
       "      <td>-0.899872</td>\n",
       "      <td>-0.843321</td>\n",
       "      <td>-0.714901</td>\n",
       "      <td>-0.763757</td>\n",
       "      <td>-0.568146</td>\n",
       "      <td>-0.206103</td>\n",
       "      <td>-0.661909</td>\n",
       "      <td>-0.543450</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.209678</td>\n",
       "      <td>-0.225520</td>\n",
       "      <td>-0.539244</td>\n",
       "      <td>-0.160583</td>\n",
       "      <td>-0.356047</td>\n",
       "      <td>-0.318619</td>\n",
       "      <td>-0.327343</td>\n",
       "      <td>-0.070558</td>\n",
       "      <td>-0.052189</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.075358</td>\n",
       "      <td>0.180610</td>\n",
       "      <td>-0.008844</td>\n",
       "      <td>-0.060040</td>\n",
       "      <td>-0.271363</td>\n",
       "      <td>0.036107</td>\n",
       "      <td>0.022463</td>\n",
       "      <td>-0.055095</td>\n",
       "      <td>-0.097390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062792</td>\n",
       "      <td>-0.028778</td>\n",
       "      <td>0.007302</td>\n",
       "      <td>-0.011199</td>\n",
       "      <td>0.040006</td>\n",
       "      <td>0.019770</td>\n",
       "      <td>-0.056260</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.317461</td>\n",
       "      <td>0.806957</td>\n",
       "      <td>1.029928</td>\n",
       "      <td>0.771958</td>\n",
       "      <td>0.613328</td>\n",
       "      <td>0.397269</td>\n",
       "      <td>0.559409</td>\n",
       "      <td>0.329606</td>\n",
       "      <td>0.605704</td>\n",
       "      <td>0.460681</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131199</td>\n",
       "      <td>0.184312</td>\n",
       "      <td>0.526358</td>\n",
       "      <td>0.146835</td>\n",
       "      <td>0.437146</td>\n",
       "      <td>0.352717</td>\n",
       "      <td>0.240713</td>\n",
       "      <td>0.091637</td>\n",
       "      <td>0.078911</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.399484</td>\n",
       "      <td>21.467203</td>\n",
       "      <td>4.069865</td>\n",
       "      <td>11.927512</td>\n",
       "      <td>32.911462</td>\n",
       "      <td>22.529298</td>\n",
       "      <td>36.677268</td>\n",
       "      <td>20.007208</td>\n",
       "      <td>8.113152</td>\n",
       "      <td>15.236028</td>\n",
       "      <td>...</td>\n",
       "      <td>26.237391</td>\n",
       "      <td>27.202839</td>\n",
       "      <td>8.361985</td>\n",
       "      <td>9.637187</td>\n",
       "      <td>3.948061</td>\n",
       "      <td>2.510401</td>\n",
       "      <td>3.122747</td>\n",
       "      <td>11.135740</td>\n",
       "      <td>14.929133</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 V1            V2            V3            V4            V5  \\\n",
       "count  28678.000000  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean      -0.015438      0.053653     -0.046031      0.037348     -0.033724   \n",
       "std        2.031529      1.616186      1.758169      1.482109      1.486998   \n",
       "min      -30.552380    -42.172688    -31.103685     -5.560118    -42.147898   \n",
       "25%       -0.916927     -0.575381     -0.899872     -0.843321     -0.714901   \n",
       "50%        0.020050      0.075358      0.180610     -0.008844     -0.060040   \n",
       "75%        1.317461      0.806957      1.029928      0.771958      0.613328   \n",
       "max        2.399484     21.467203      4.069865     11.927512     32.911462   \n",
       "\n",
       "                 V6            V7            V8            V9           V10  \\\n",
       "count  28678.000000  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean      -0.003299     -0.051054      0.006064     -0.018530     -0.041149   \n",
       "std        1.339259      1.454827      1.364342      1.134065      1.252593   \n",
       "min      -21.929312    -41.506796    -39.267378    -13.434066    -24.403185   \n",
       "25%       -0.763757     -0.568146     -0.206103     -0.661909     -0.543450   \n",
       "50%       -0.271363      0.036107      0.022463     -0.055095     -0.097390   \n",
       "75%        0.397269      0.559409      0.329606      0.605704      0.460681   \n",
       "max       22.529298     36.677268     20.007208      8.113152     15.236028   \n",
       "\n",
       "       ...           V20           V21           V22           V23  \\\n",
       "count  ...  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean   ...      0.002633      0.010289     -0.000656     -0.004800   \n",
       "std    ...      0.720307      0.847152      0.739469      0.593663   \n",
       "min    ...    -21.387122    -21.453736     -8.887017    -36.666000   \n",
       "25%    ...     -0.209678     -0.225520     -0.539244     -0.160583   \n",
       "50%    ...     -0.062792     -0.028778      0.007302     -0.011199   \n",
       "75%    ...      0.131199      0.184312      0.526358      0.146835   \n",
       "max    ...     26.237391     27.202839      8.361985      9.637187   \n",
       "\n",
       "                V24           V25           V26           V27           V28  \\\n",
       "count  28678.000000  28678.000000  28678.000000  28678.000000  28678.000000   \n",
       "mean      -0.000897     -0.001989     -0.000765      0.000948      0.001535   \n",
       "std        0.603349      0.517968      0.483852      0.397075      0.296736   \n",
       "min       -2.718024     -6.712624     -2.241620     -7.418878     -9.617915   \n",
       "25%       -0.356047     -0.318619     -0.327343     -0.070558     -0.052189   \n",
       "50%        0.040006      0.019770     -0.056260      0.002049      0.011075   \n",
       "75%        0.437146      0.352717      0.240713      0.091637      0.078911   \n",
       "max        3.948061      2.510401      3.122747     11.135740     14.929133   \n",
       "\n",
       "              Class  \n",
       "count  28678.000000  \n",
       "mean       0.008578  \n",
       "std        0.092221  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    우선 describe 함수를 사용하여 변수에 대한 요약적인 정보를 파악한다. 변수들의 min, max값을 봤을 때 들쭉날쭉 하므로 scaling이 이루어져야 한다. 하지만 지금 상태로 scaling을 하게 되면 Class 역시 값이 바뀌게 되므로 Class는 따로 빼둔 뒤, 나중에 다시 데이터 프레임에 합치기로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "28673    0\n",
       "28674    0\n",
       "28675    0\n",
       "28676    0\n",
       "28677    0\n",
       "Name: Class, Length: 28678, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_class = credit['Class']\n",
    "credit_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min max 값의 차이가 서로 크므로 scaling을 진행한다.\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90218019,  1.44246214,  0.24207645, ..., -0.04709654,\n",
       "         0.9417547 , -0.09301733],\n",
       "       [ 1.02744235, -0.32892601, -0.7953942 , ..., -0.23721911,\n",
       "        -0.22629752, -0.09301733],\n",
       "       [-1.46190736, -1.73320058,  0.7053479 , ..., -0.7554671 ,\n",
       "        -1.02943014, -0.09301733],\n",
       "       ...,\n",
       "       [ 1.02786291,  0.0843943 , -0.9747001 , ..., -0.15087861,\n",
       "        -0.1030219 , -0.09301733],\n",
       "       [-0.33236542,  0.79733419,  0.8782926 , ..., -2.140772  ,\n",
       "        -1.05999649, -0.09301733],\n",
       "       [ 1.09831537, -0.52987507, -0.90637085, ..., -0.13776702,\n",
       "        -0.2565925 , -0.09301733]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.902180</td>\n",
       "      <td>1.442462</td>\n",
       "      <td>0.242076</td>\n",
       "      <td>0.682170</td>\n",
       "      <td>-0.545636</td>\n",
       "      <td>1.897453</td>\n",
       "      <td>-3.087657</td>\n",
       "      <td>-7.481774</td>\n",
       "      <td>-1.310739</td>\n",
       "      <td>-1.750813</td>\n",
       "      <td>...</td>\n",
       "      <td>3.586292</td>\n",
       "      <td>-6.258702</td>\n",
       "      <td>1.163043</td>\n",
       "      <td>0.721013</td>\n",
       "      <td>-0.838813</td>\n",
       "      <td>1.973207</td>\n",
       "      <td>-1.295843</td>\n",
       "      <td>-0.047097</td>\n",
       "      <td>0.941755</td>\n",
       "      <td>-0.093017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.027442</td>\n",
       "      <td>-0.328926</td>\n",
       "      <td>-0.795394</td>\n",
       "      <td>-0.395393</td>\n",
       "      <td>0.029429</td>\n",
       "      <td>-0.432294</td>\n",
       "      <td>0.005620</td>\n",
       "      <td>-0.185605</td>\n",
       "      <td>1.049741</td>\n",
       "      <td>-0.240491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110982</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>0.528470</td>\n",
       "      <td>0.078108</td>\n",
       "      <td>0.993348</td>\n",
       "      <td>0.194594</td>\n",
       "      <td>2.026379</td>\n",
       "      <td>-0.237219</td>\n",
       "      <td>-0.226298</td>\n",
       "      <td>-0.093017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.461907</td>\n",
       "      <td>-1.733201</td>\n",
       "      <td>0.705348</td>\n",
       "      <td>-0.027248</td>\n",
       "      <td>-0.751404</td>\n",
       "      <td>-0.194335</td>\n",
       "      <td>0.415558</td>\n",
       "      <td>0.461429</td>\n",
       "      <td>0.403048</td>\n",
       "      <td>-1.409372</td>\n",
       "      <td>...</td>\n",
       "      <td>1.864714</td>\n",
       "      <td>0.429058</td>\n",
       "      <td>-0.520817</td>\n",
       "      <td>2.025422</td>\n",
       "      <td>0.676446</td>\n",
       "      <td>0.019311</td>\n",
       "      <td>1.577217</td>\n",
       "      <td>-0.755467</td>\n",
       "      <td>-1.029430</td>\n",
       "      <td>-0.093017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.720659</td>\n",
       "      <td>0.921458</td>\n",
       "      <td>0.191638</td>\n",
       "      <td>0.540317</td>\n",
       "      <td>-0.333272</td>\n",
       "      <td>-0.533410</td>\n",
       "      <td>0.368140</td>\n",
       "      <td>0.395090</td>\n",
       "      <td>-0.672139</td>\n",
       "      <td>0.292162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049651</td>\n",
       "      <td>0.125696</td>\n",
       "      <td>0.549344</td>\n",
       "      <td>-0.188079</td>\n",
       "      <td>0.898622</td>\n",
       "      <td>-0.414465</td>\n",
       "      <td>-0.857327</td>\n",
       "      <td>0.065929</td>\n",
       "      <td>-0.511850</td>\n",
       "      <td>-0.093017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.131203</td>\n",
       "      <td>-0.224824</td>\n",
       "      <td>-1.203698</td>\n",
       "      <td>-0.599739</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>-1.105548</td>\n",
       "      <td>1.362418</td>\n",
       "      <td>-0.622372</td>\n",
       "      <td>-1.085267</td>\n",
       "      <td>0.894765</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.219154</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>1.373663</td>\n",
       "      <td>-0.036971</td>\n",
       "      <td>0.129301</td>\n",
       "      <td>-2.831946</td>\n",
       "      <td>1.555181</td>\n",
       "      <td>1.248615</td>\n",
       "      <td>1.110322</td>\n",
       "      <td>-0.093017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28673</th>\n",
       "      <td>1.023255</td>\n",
       "      <td>-0.023908</td>\n",
       "      <td>-0.566583</td>\n",
       "      <td>0.251205</td>\n",
       "      <td>-0.024285</td>\n",
       "      <td>-0.892442</td>\n",
       "      <td>0.202475</td>\n",
       "      <td>-0.286709</td>\n",
       "      <td>0.376723</td>\n",
       "      <td>0.071062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239323</td>\n",
       "      <td>-0.341422</td>\n",
       "      <td>-0.845179</td>\n",
       "      <td>0.566116</td>\n",
       "      <td>0.117848</td>\n",
       "      <td>-0.517101</td>\n",
       "      <td>0.399455</td>\n",
       "      <td>-0.165871</td>\n",
       "      <td>-0.200830</td>\n",
       "      <td>-0.093017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28674</th>\n",
       "      <td>0.630217</td>\n",
       "      <td>-0.793406</td>\n",
       "      <td>0.924346</td>\n",
       "      <td>-0.163191</td>\n",
       "      <td>-1.294682</td>\n",
       "      <td>0.410528</td>\n",
       "      <td>-1.177492</td>\n",
       "      <td>0.340326</td>\n",
       "      <td>0.900087</td>\n",
       "      <td>0.251606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177753</td>\n",
       "      <td>0.158912</td>\n",
       "      <td>0.972702</td>\n",
       "      <td>-0.056755</td>\n",
       "      <td>0.173374</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>-0.018687</td>\n",
       "      <td>0.223756</td>\n",
       "      <td>0.061716</td>\n",
       "      <td>-0.093017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28675</th>\n",
       "      <td>1.027863</td>\n",
       "      <td>0.084394</td>\n",
       "      <td>-0.974700</td>\n",
       "      <td>0.230460</td>\n",
       "      <td>0.397149</td>\n",
       "      <td>-0.572397</td>\n",
       "      <td>0.204807</td>\n",
       "      <td>-0.205689</td>\n",
       "      <td>0.352270</td>\n",
       "      <td>-0.290601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120511</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>-1.230805</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>0.666969</td>\n",
       "      <td>-0.406308</td>\n",
       "      <td>0.369172</td>\n",
       "      <td>-0.150879</td>\n",
       "      <td>-0.103022</td>\n",
       "      <td>-0.093017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28676</th>\n",
       "      <td>-0.332365</td>\n",
       "      <td>0.797334</td>\n",
       "      <td>0.878293</td>\n",
       "      <td>1.357837</td>\n",
       "      <td>0.732640</td>\n",
       "      <td>0.508122</td>\n",
       "      <td>0.623108</td>\n",
       "      <td>-0.346918</td>\n",
       "      <td>-0.584673</td>\n",
       "      <td>1.218846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039199</td>\n",
       "      <td>0.118811</td>\n",
       "      <td>0.613586</td>\n",
       "      <td>-0.590491</td>\n",
       "      <td>-1.276522</td>\n",
       "      <td>-0.688309</td>\n",
       "      <td>0.210966</td>\n",
       "      <td>-2.140772</td>\n",
       "      <td>-1.059996</td>\n",
       "      <td>-0.093017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28677</th>\n",
       "      <td>1.098315</td>\n",
       "      <td>-0.529875</td>\n",
       "      <td>-0.906371</td>\n",
       "      <td>-0.777389</td>\n",
       "      <td>-0.066633</td>\n",
       "      <td>-0.285113</td>\n",
       "      <td>-0.291152</td>\n",
       "      <td>-0.042402</td>\n",
       "      <td>-0.444799</td>\n",
       "      <td>0.822563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147357</td>\n",
       "      <td>0.028141</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.337860</td>\n",
       "      <td>0.438380</td>\n",
       "      <td>-0.054341</td>\n",
       "      <td>-0.615476</td>\n",
       "      <td>-0.137767</td>\n",
       "      <td>-0.256593</td>\n",
       "      <td>-0.093017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28678 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     -0.902180  1.442462  0.242076  0.682170 -0.545636  1.897453 -3.087657   \n",
       "1      1.027442 -0.328926 -0.795394 -0.395393  0.029429 -0.432294  0.005620   \n",
       "2     -1.461907 -1.733201  0.705348 -0.027248 -0.751404 -0.194335  0.415558   \n",
       "3     -0.720659  0.921458  0.191638  0.540317 -0.333272 -0.533410  0.368140   \n",
       "4     -0.131203 -0.224824 -1.203698 -0.599739  0.094078 -1.105548  1.362418   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "28673  1.023255 -0.023908 -0.566583  0.251205 -0.024285 -0.892442  0.202475   \n",
       "28674  0.630217 -0.793406  0.924346 -0.163191 -1.294682  0.410528 -1.177492   \n",
       "28675  1.027863  0.084394 -0.974700  0.230460  0.397149 -0.572397  0.204807   \n",
       "28676 -0.332365  0.797334  0.878293  1.357837  0.732640  0.508122  0.623108   \n",
       "28677  1.098315 -0.529875 -0.906371 -0.777389 -0.066633 -0.285113 -0.291152   \n",
       "\n",
       "             V8        V9       V10  ...       V20       V21       V22  \\\n",
       "0     -7.481774 -1.310739 -1.750813  ...  3.586292 -6.258702  1.163043   \n",
       "1     -0.185605  1.049741 -0.240491  ... -0.110982  0.038445  0.528470   \n",
       "2      0.461429  0.403048 -1.409372  ...  1.864714  0.429058 -0.520817   \n",
       "3      0.395090 -0.672139  0.292162  ...  0.049651  0.125696  0.549344   \n",
       "4     -0.622372 -1.085267  0.894765  ... -1.219154 -0.017103  1.373663   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "28673 -0.286709  0.376723  0.071062  ... -0.239323 -0.341422 -0.845179   \n",
       "28674  0.340326  0.900087  0.251606  ... -0.177753  0.158912  0.972702   \n",
       "28675 -0.205689  0.352270 -0.290601  ... -0.120511 -0.438509 -1.230805   \n",
       "28676 -0.346918 -0.584673  1.218846  ...  0.039199  0.118811  0.613586   \n",
       "28677 -0.042402 -0.444799  0.822563  ... -0.147357  0.028141  0.031081   \n",
       "\n",
       "            V23       V24       V25       V26       V27       V28     Class  \n",
       "0      0.721013 -0.838813  1.973207 -1.295843 -0.047097  0.941755 -0.093017  \n",
       "1      0.078108  0.993348  0.194594  2.026379 -0.237219 -0.226298 -0.093017  \n",
       "2      2.025422  0.676446  0.019311  1.577217 -0.755467 -1.029430 -0.093017  \n",
       "3     -0.188079  0.898622 -0.414465 -0.857327  0.065929 -0.511850 -0.093017  \n",
       "4     -0.036971  0.129301 -2.831946  1.555181  1.248615  1.110322 -0.093017  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "28673  0.566116  0.117848 -0.517101  0.399455 -0.165871 -0.200830 -0.093017  \n",
       "28674 -0.056755  0.173374  0.662386 -0.018687  0.223756  0.061716 -0.093017  \n",
       "28675  0.520796  0.666969 -0.406308  0.369172 -0.150879 -0.103022 -0.093017  \n",
       "28676 -0.590491 -1.276522 -0.688309  0.210966 -2.140772 -1.059996 -0.093017  \n",
       "28677  0.337860  0.438380 -0.054341 -0.615476 -0.137767 -0.256593 -0.093017  \n",
       "\n",
       "[28678 rows x 29 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit = pd.DataFrame(scaler.fit_transform(credit), columns = credit.columns)\n",
    "credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    여기서 보면 알 수 있듯이, scaling을 함으로써 Class값이 바뀐 것을 알 수 있다. logistic regression 모델에 y값을 적합 시킬 때, y = 0 or 1의 값을 가져야 한다. 지금 이 상태라면 후에 모델 적합 시, 오류가 날 것이므로 아래의 과정을 통해 Class 값을 다시 0과 1로 바꿔준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.902180</td>\n",
       "      <td>1.442462</td>\n",
       "      <td>0.242076</td>\n",
       "      <td>0.682170</td>\n",
       "      <td>-0.545636</td>\n",
       "      <td>1.897453</td>\n",
       "      <td>-3.087657</td>\n",
       "      <td>-7.481774</td>\n",
       "      <td>-1.310739</td>\n",
       "      <td>-1.750813</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184394</td>\n",
       "      <td>3.586292</td>\n",
       "      <td>-6.258702</td>\n",
       "      <td>1.163043</td>\n",
       "      <td>0.721013</td>\n",
       "      <td>-0.838813</td>\n",
       "      <td>1.973207</td>\n",
       "      <td>-1.295843</td>\n",
       "      <td>-0.047097</td>\n",
       "      <td>0.941755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.027442</td>\n",
       "      <td>-0.328926</td>\n",
       "      <td>-0.795394</td>\n",
       "      <td>-0.395393</td>\n",
       "      <td>0.029429</td>\n",
       "      <td>-0.432294</td>\n",
       "      <td>0.005620</td>\n",
       "      <td>-0.185605</td>\n",
       "      <td>1.049741</td>\n",
       "      <td>-0.240491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770828</td>\n",
       "      <td>-0.110982</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>0.528470</td>\n",
       "      <td>0.078108</td>\n",
       "      <td>0.993348</td>\n",
       "      <td>0.194594</td>\n",
       "      <td>2.026379</td>\n",
       "      <td>-0.237219</td>\n",
       "      <td>-0.226298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.461907</td>\n",
       "      <td>-1.733201</td>\n",
       "      <td>0.705348</td>\n",
       "      <td>-0.027248</td>\n",
       "      <td>-0.751404</td>\n",
       "      <td>-0.194335</td>\n",
       "      <td>0.415558</td>\n",
       "      <td>0.461429</td>\n",
       "      <td>0.403048</td>\n",
       "      <td>-1.409372</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.078858</td>\n",
       "      <td>1.864714</td>\n",
       "      <td>0.429058</td>\n",
       "      <td>-0.520817</td>\n",
       "      <td>2.025422</td>\n",
       "      <td>0.676446</td>\n",
       "      <td>0.019311</td>\n",
       "      <td>1.577217</td>\n",
       "      <td>-0.755467</td>\n",
       "      <td>-1.029430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.720659</td>\n",
       "      <td>0.921458</td>\n",
       "      <td>0.191638</td>\n",
       "      <td>0.540317</td>\n",
       "      <td>-0.333272</td>\n",
       "      <td>-0.533410</td>\n",
       "      <td>0.368140</td>\n",
       "      <td>0.395090</td>\n",
       "      <td>-0.672139</td>\n",
       "      <td>0.292162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793099</td>\n",
       "      <td>0.049651</td>\n",
       "      <td>0.125696</td>\n",
       "      <td>0.549344</td>\n",
       "      <td>-0.188079</td>\n",
       "      <td>0.898622</td>\n",
       "      <td>-0.414465</td>\n",
       "      <td>-0.857327</td>\n",
       "      <td>0.065929</td>\n",
       "      <td>-0.511850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.131203</td>\n",
       "      <td>-0.224824</td>\n",
       "      <td>-1.203698</td>\n",
       "      <td>-0.599739</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>-1.105548</td>\n",
       "      <td>1.362418</td>\n",
       "      <td>-0.622372</td>\n",
       "      <td>-1.085267</td>\n",
       "      <td>0.894765</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.651400</td>\n",
       "      <td>-1.219154</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>1.373663</td>\n",
       "      <td>-0.036971</td>\n",
       "      <td>0.129301</td>\n",
       "      <td>-2.831946</td>\n",
       "      <td>1.555181</td>\n",
       "      <td>1.248615</td>\n",
       "      <td>1.110322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28673</th>\n",
       "      <td>1.023255</td>\n",
       "      <td>-0.023908</td>\n",
       "      <td>-0.566583</td>\n",
       "      <td>0.251205</td>\n",
       "      <td>-0.024285</td>\n",
       "      <td>-0.892442</td>\n",
       "      <td>0.202475</td>\n",
       "      <td>-0.286709</td>\n",
       "      <td>0.376723</td>\n",
       "      <td>0.071062</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156931</td>\n",
       "      <td>-0.239323</td>\n",
       "      <td>-0.341422</td>\n",
       "      <td>-0.845179</td>\n",
       "      <td>0.566116</td>\n",
       "      <td>0.117848</td>\n",
       "      <td>-0.517101</td>\n",
       "      <td>0.399455</td>\n",
       "      <td>-0.165871</td>\n",
       "      <td>-0.200830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28674</th>\n",
       "      <td>0.630217</td>\n",
       "      <td>-0.793406</td>\n",
       "      <td>0.924346</td>\n",
       "      <td>-0.163191</td>\n",
       "      <td>-1.294682</td>\n",
       "      <td>0.410528</td>\n",
       "      <td>-1.177492</td>\n",
       "      <td>0.340326</td>\n",
       "      <td>0.900087</td>\n",
       "      <td>0.251606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.769189</td>\n",
       "      <td>-0.177753</td>\n",
       "      <td>0.158912</td>\n",
       "      <td>0.972702</td>\n",
       "      <td>-0.056755</td>\n",
       "      <td>0.173374</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>-0.018687</td>\n",
       "      <td>0.223756</td>\n",
       "      <td>0.061716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28675</th>\n",
       "      <td>1.027863</td>\n",
       "      <td>0.084394</td>\n",
       "      <td>-0.974700</td>\n",
       "      <td>0.230460</td>\n",
       "      <td>0.397149</td>\n",
       "      <td>-0.572397</td>\n",
       "      <td>0.204807</td>\n",
       "      <td>-0.205689</td>\n",
       "      <td>0.352270</td>\n",
       "      <td>-0.290601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117016</td>\n",
       "      <td>-0.120511</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>-1.230805</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>0.666969</td>\n",
       "      <td>-0.406308</td>\n",
       "      <td>0.369172</td>\n",
       "      <td>-0.150879</td>\n",
       "      <td>-0.103022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28676</th>\n",
       "      <td>-0.332365</td>\n",
       "      <td>0.797334</td>\n",
       "      <td>0.878293</td>\n",
       "      <td>1.357837</td>\n",
       "      <td>0.732640</td>\n",
       "      <td>0.508122</td>\n",
       "      <td>0.623108</td>\n",
       "      <td>-0.346918</td>\n",
       "      <td>-0.584673</td>\n",
       "      <td>1.218846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060428</td>\n",
       "      <td>0.039199</td>\n",
       "      <td>0.118811</td>\n",
       "      <td>0.613586</td>\n",
       "      <td>-0.590491</td>\n",
       "      <td>-1.276522</td>\n",
       "      <td>-0.688309</td>\n",
       "      <td>0.210966</td>\n",
       "      <td>-2.140772</td>\n",
       "      <td>-1.059996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28677</th>\n",
       "      <td>1.098315</td>\n",
       "      <td>-0.529875</td>\n",
       "      <td>-0.906371</td>\n",
       "      <td>-0.777389</td>\n",
       "      <td>-0.066633</td>\n",
       "      <td>-0.285113</td>\n",
       "      <td>-0.291152</td>\n",
       "      <td>-0.042402</td>\n",
       "      <td>-0.444799</td>\n",
       "      <td>0.822563</td>\n",
       "      <td>...</td>\n",
       "      <td>1.456024</td>\n",
       "      <td>-0.147357</td>\n",
       "      <td>0.028141</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.337860</td>\n",
       "      <td>0.438380</td>\n",
       "      <td>-0.054341</td>\n",
       "      <td>-0.615476</td>\n",
       "      <td>-0.137767</td>\n",
       "      <td>-0.256593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28678 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     -0.902180  1.442462  0.242076  0.682170 -0.545636  1.897453 -3.087657   \n",
       "1      1.027442 -0.328926 -0.795394 -0.395393  0.029429 -0.432294  0.005620   \n",
       "2     -1.461907 -1.733201  0.705348 -0.027248 -0.751404 -0.194335  0.415558   \n",
       "3     -0.720659  0.921458  0.191638  0.540317 -0.333272 -0.533410  0.368140   \n",
       "4     -0.131203 -0.224824 -1.203698 -0.599739  0.094078 -1.105548  1.362418   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "28673  1.023255 -0.023908 -0.566583  0.251205 -0.024285 -0.892442  0.202475   \n",
       "28674  0.630217 -0.793406  0.924346 -0.163191 -1.294682  0.410528 -1.177492   \n",
       "28675  1.027863  0.084394 -0.974700  0.230460  0.397149 -0.572397  0.204807   \n",
       "28676 -0.332365  0.797334  0.878293  1.357837  0.732640  0.508122  0.623108   \n",
       "28677  1.098315 -0.529875 -0.906371 -0.777389 -0.066633 -0.285113 -0.291152   \n",
       "\n",
       "             V8        V9       V10  ...       V19       V20       V21  \\\n",
       "0     -7.481774 -1.310739 -1.750813  ...  0.184394  3.586292 -6.258702   \n",
       "1     -0.185605  1.049741 -0.240491  ...  0.770828 -0.110982  0.038445   \n",
       "2      0.461429  0.403048 -1.409372  ... -1.078858  1.864714  0.429058   \n",
       "3      0.395090 -0.672139  0.292162  ...  0.793099  0.049651  0.125696   \n",
       "4     -0.622372 -1.085267  0.894765  ... -0.651400 -1.219154 -0.017103   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "28673 -0.286709  0.376723  0.071062  ...  0.156931 -0.239323 -0.341422   \n",
       "28674  0.340326  0.900087  0.251606  ...  0.769189 -0.177753  0.158912   \n",
       "28675 -0.205689  0.352270 -0.290601  ...  0.117016 -0.120511 -0.438509   \n",
       "28676 -0.346918 -0.584673  1.218846  ...  0.060428  0.039199  0.118811   \n",
       "28677 -0.042402 -0.444799  0.822563  ...  1.456024 -0.147357  0.028141   \n",
       "\n",
       "            V22       V23       V24       V25       V26       V27       V28  \n",
       "0      1.163043  0.721013 -0.838813  1.973207 -1.295843 -0.047097  0.941755  \n",
       "1      0.528470  0.078108  0.993348  0.194594  2.026379 -0.237219 -0.226298  \n",
       "2     -0.520817  2.025422  0.676446  0.019311  1.577217 -0.755467 -1.029430  \n",
       "3      0.549344 -0.188079  0.898622 -0.414465 -0.857327  0.065929 -0.511850  \n",
       "4      1.373663 -0.036971  0.129301 -2.831946  1.555181  1.248615  1.110322  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "28673 -0.845179  0.566116  0.117848 -0.517101  0.399455 -0.165871 -0.200830  \n",
       "28674  0.972702 -0.056755  0.173374  0.662386 -0.018687  0.223756  0.061716  \n",
       "28675 -1.230805  0.520796  0.666969 -0.406308  0.369172 -0.150879 -0.103022  \n",
       "28676  0.613586 -0.590491 -1.276522 -0.688309  0.210966 -2.140772 -1.059996  \n",
       "28677  0.031081  0.337860  0.438380 -0.054341 -0.615476 -0.137767 -0.256593  \n",
       "\n",
       "[28678 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit = credit.drop(['Class'], axis =1)\n",
    "credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.902180</td>\n",
       "      <td>1.442462</td>\n",
       "      <td>0.242076</td>\n",
       "      <td>0.682170</td>\n",
       "      <td>-0.545636</td>\n",
       "      <td>1.897453</td>\n",
       "      <td>-3.087657</td>\n",
       "      <td>-7.481774</td>\n",
       "      <td>-1.310739</td>\n",
       "      <td>-1.750813</td>\n",
       "      <td>...</td>\n",
       "      <td>3.586292</td>\n",
       "      <td>-6.258702</td>\n",
       "      <td>1.163043</td>\n",
       "      <td>0.721013</td>\n",
       "      <td>-0.838813</td>\n",
       "      <td>1.973207</td>\n",
       "      <td>-1.295843</td>\n",
       "      <td>-0.047097</td>\n",
       "      <td>0.941755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.027442</td>\n",
       "      <td>-0.328926</td>\n",
       "      <td>-0.795394</td>\n",
       "      <td>-0.395393</td>\n",
       "      <td>0.029429</td>\n",
       "      <td>-0.432294</td>\n",
       "      <td>0.005620</td>\n",
       "      <td>-0.185605</td>\n",
       "      <td>1.049741</td>\n",
       "      <td>-0.240491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110982</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>0.528470</td>\n",
       "      <td>0.078108</td>\n",
       "      <td>0.993348</td>\n",
       "      <td>0.194594</td>\n",
       "      <td>2.026379</td>\n",
       "      <td>-0.237219</td>\n",
       "      <td>-0.226298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.461907</td>\n",
       "      <td>-1.733201</td>\n",
       "      <td>0.705348</td>\n",
       "      <td>-0.027248</td>\n",
       "      <td>-0.751404</td>\n",
       "      <td>-0.194335</td>\n",
       "      <td>0.415558</td>\n",
       "      <td>0.461429</td>\n",
       "      <td>0.403048</td>\n",
       "      <td>-1.409372</td>\n",
       "      <td>...</td>\n",
       "      <td>1.864714</td>\n",
       "      <td>0.429058</td>\n",
       "      <td>-0.520817</td>\n",
       "      <td>2.025422</td>\n",
       "      <td>0.676446</td>\n",
       "      <td>0.019311</td>\n",
       "      <td>1.577217</td>\n",
       "      <td>-0.755467</td>\n",
       "      <td>-1.029430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.720659</td>\n",
       "      <td>0.921458</td>\n",
       "      <td>0.191638</td>\n",
       "      <td>0.540317</td>\n",
       "      <td>-0.333272</td>\n",
       "      <td>-0.533410</td>\n",
       "      <td>0.368140</td>\n",
       "      <td>0.395090</td>\n",
       "      <td>-0.672139</td>\n",
       "      <td>0.292162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049651</td>\n",
       "      <td>0.125696</td>\n",
       "      <td>0.549344</td>\n",
       "      <td>-0.188079</td>\n",
       "      <td>0.898622</td>\n",
       "      <td>-0.414465</td>\n",
       "      <td>-0.857327</td>\n",
       "      <td>0.065929</td>\n",
       "      <td>-0.511850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.131203</td>\n",
       "      <td>-0.224824</td>\n",
       "      <td>-1.203698</td>\n",
       "      <td>-0.599739</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>-1.105548</td>\n",
       "      <td>1.362418</td>\n",
       "      <td>-0.622372</td>\n",
       "      <td>-1.085267</td>\n",
       "      <td>0.894765</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.219154</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>1.373663</td>\n",
       "      <td>-0.036971</td>\n",
       "      <td>0.129301</td>\n",
       "      <td>-2.831946</td>\n",
       "      <td>1.555181</td>\n",
       "      <td>1.248615</td>\n",
       "      <td>1.110322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28673</th>\n",
       "      <td>1.023255</td>\n",
       "      <td>-0.023908</td>\n",
       "      <td>-0.566583</td>\n",
       "      <td>0.251205</td>\n",
       "      <td>-0.024285</td>\n",
       "      <td>-0.892442</td>\n",
       "      <td>0.202475</td>\n",
       "      <td>-0.286709</td>\n",
       "      <td>0.376723</td>\n",
       "      <td>0.071062</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.239323</td>\n",
       "      <td>-0.341422</td>\n",
       "      <td>-0.845179</td>\n",
       "      <td>0.566116</td>\n",
       "      <td>0.117848</td>\n",
       "      <td>-0.517101</td>\n",
       "      <td>0.399455</td>\n",
       "      <td>-0.165871</td>\n",
       "      <td>-0.200830</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28674</th>\n",
       "      <td>0.630217</td>\n",
       "      <td>-0.793406</td>\n",
       "      <td>0.924346</td>\n",
       "      <td>-0.163191</td>\n",
       "      <td>-1.294682</td>\n",
       "      <td>0.410528</td>\n",
       "      <td>-1.177492</td>\n",
       "      <td>0.340326</td>\n",
       "      <td>0.900087</td>\n",
       "      <td>0.251606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177753</td>\n",
       "      <td>0.158912</td>\n",
       "      <td>0.972702</td>\n",
       "      <td>-0.056755</td>\n",
       "      <td>0.173374</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>-0.018687</td>\n",
       "      <td>0.223756</td>\n",
       "      <td>0.061716</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28675</th>\n",
       "      <td>1.027863</td>\n",
       "      <td>0.084394</td>\n",
       "      <td>-0.974700</td>\n",
       "      <td>0.230460</td>\n",
       "      <td>0.397149</td>\n",
       "      <td>-0.572397</td>\n",
       "      <td>0.204807</td>\n",
       "      <td>-0.205689</td>\n",
       "      <td>0.352270</td>\n",
       "      <td>-0.290601</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.120511</td>\n",
       "      <td>-0.438509</td>\n",
       "      <td>-1.230805</td>\n",
       "      <td>0.520796</td>\n",
       "      <td>0.666969</td>\n",
       "      <td>-0.406308</td>\n",
       "      <td>0.369172</td>\n",
       "      <td>-0.150879</td>\n",
       "      <td>-0.103022</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28676</th>\n",
       "      <td>-0.332365</td>\n",
       "      <td>0.797334</td>\n",
       "      <td>0.878293</td>\n",
       "      <td>1.357837</td>\n",
       "      <td>0.732640</td>\n",
       "      <td>0.508122</td>\n",
       "      <td>0.623108</td>\n",
       "      <td>-0.346918</td>\n",
       "      <td>-0.584673</td>\n",
       "      <td>1.218846</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039199</td>\n",
       "      <td>0.118811</td>\n",
       "      <td>0.613586</td>\n",
       "      <td>-0.590491</td>\n",
       "      <td>-1.276522</td>\n",
       "      <td>-0.688309</td>\n",
       "      <td>0.210966</td>\n",
       "      <td>-2.140772</td>\n",
       "      <td>-1.059996</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28677</th>\n",
       "      <td>1.098315</td>\n",
       "      <td>-0.529875</td>\n",
       "      <td>-0.906371</td>\n",
       "      <td>-0.777389</td>\n",
       "      <td>-0.066633</td>\n",
       "      <td>-0.285113</td>\n",
       "      <td>-0.291152</td>\n",
       "      <td>-0.042402</td>\n",
       "      <td>-0.444799</td>\n",
       "      <td>0.822563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147357</td>\n",
       "      <td>0.028141</td>\n",
       "      <td>0.031081</td>\n",
       "      <td>0.337860</td>\n",
       "      <td>0.438380</td>\n",
       "      <td>-0.054341</td>\n",
       "      <td>-0.615476</td>\n",
       "      <td>-0.137767</td>\n",
       "      <td>-0.256593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28678 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     -0.902180  1.442462  0.242076  0.682170 -0.545636  1.897453 -3.087657   \n",
       "1      1.027442 -0.328926 -0.795394 -0.395393  0.029429 -0.432294  0.005620   \n",
       "2     -1.461907 -1.733201  0.705348 -0.027248 -0.751404 -0.194335  0.415558   \n",
       "3     -0.720659  0.921458  0.191638  0.540317 -0.333272 -0.533410  0.368140   \n",
       "4     -0.131203 -0.224824 -1.203698 -0.599739  0.094078 -1.105548  1.362418   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "28673  1.023255 -0.023908 -0.566583  0.251205 -0.024285 -0.892442  0.202475   \n",
       "28674  0.630217 -0.793406  0.924346 -0.163191 -1.294682  0.410528 -1.177492   \n",
       "28675  1.027863  0.084394 -0.974700  0.230460  0.397149 -0.572397  0.204807   \n",
       "28676 -0.332365  0.797334  0.878293  1.357837  0.732640  0.508122  0.623108   \n",
       "28677  1.098315 -0.529875 -0.906371 -0.777389 -0.066633 -0.285113 -0.291152   \n",
       "\n",
       "             V8        V9       V10  ...       V20       V21       V22  \\\n",
       "0     -7.481774 -1.310739 -1.750813  ...  3.586292 -6.258702  1.163043   \n",
       "1     -0.185605  1.049741 -0.240491  ... -0.110982  0.038445  0.528470   \n",
       "2      0.461429  0.403048 -1.409372  ...  1.864714  0.429058 -0.520817   \n",
       "3      0.395090 -0.672139  0.292162  ...  0.049651  0.125696  0.549344   \n",
       "4     -0.622372 -1.085267  0.894765  ... -1.219154 -0.017103  1.373663   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "28673 -0.286709  0.376723  0.071062  ... -0.239323 -0.341422 -0.845179   \n",
       "28674  0.340326  0.900087  0.251606  ... -0.177753  0.158912  0.972702   \n",
       "28675 -0.205689  0.352270 -0.290601  ... -0.120511 -0.438509 -1.230805   \n",
       "28676 -0.346918 -0.584673  1.218846  ...  0.039199  0.118811  0.613586   \n",
       "28677 -0.042402 -0.444799  0.822563  ... -0.147357  0.028141  0.031081   \n",
       "\n",
       "            V23       V24       V25       V26       V27       V28  Class  \n",
       "0      0.721013 -0.838813  1.973207 -1.295843 -0.047097  0.941755      0  \n",
       "1      0.078108  0.993348  0.194594  2.026379 -0.237219 -0.226298      0  \n",
       "2      2.025422  0.676446  0.019311  1.577217 -0.755467 -1.029430      0  \n",
       "3     -0.188079  0.898622 -0.414465 -0.857327  0.065929 -0.511850      0  \n",
       "4     -0.036971  0.129301 -2.831946  1.555181  1.248615  1.110322      0  \n",
       "...         ...       ...       ...       ...       ...       ...    ...  \n",
       "28673  0.566116  0.117848 -0.517101  0.399455 -0.165871 -0.200830      0  \n",
       "28674 -0.056755  0.173374  0.662386 -0.018687  0.223756  0.061716      0  \n",
       "28675  0.520796  0.666969 -0.406308  0.369172 -0.150879 -0.103022      0  \n",
       "28676 -0.590491 -1.276522 -0.688309  0.210966 -2.140772 -1.059996      0  \n",
       "28677  0.337860  0.438380 -0.054341 -0.615476 -0.137767 -0.256593      0  \n",
       "\n",
       "[28678 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit = pd.concat([credit, credit_class],axis = 1)\n",
    "credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.902180</td>\n",
       "      <td>1.442462</td>\n",
       "      <td>0.242076</td>\n",
       "      <td>0.682170</td>\n",
       "      <td>-0.545636</td>\n",
       "      <td>1.897453</td>\n",
       "      <td>-3.087657</td>\n",
       "      <td>-7.481774</td>\n",
       "      <td>-1.310739</td>\n",
       "      <td>-1.750813</td>\n",
       "      <td>...</td>\n",
       "      <td>3.586292</td>\n",
       "      <td>-6.258702</td>\n",
       "      <td>1.163043</td>\n",
       "      <td>0.721013</td>\n",
       "      <td>-0.838813</td>\n",
       "      <td>1.973207</td>\n",
       "      <td>-1.295843</td>\n",
       "      <td>-0.047097</td>\n",
       "      <td>0.941755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.027442</td>\n",
       "      <td>-0.328926</td>\n",
       "      <td>-0.795394</td>\n",
       "      <td>-0.395393</td>\n",
       "      <td>0.029429</td>\n",
       "      <td>-0.432294</td>\n",
       "      <td>0.005620</td>\n",
       "      <td>-0.185605</td>\n",
       "      <td>1.049741</td>\n",
       "      <td>-0.240491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110982</td>\n",
       "      <td>0.038445</td>\n",
       "      <td>0.528470</td>\n",
       "      <td>0.078108</td>\n",
       "      <td>0.993348</td>\n",
       "      <td>0.194594</td>\n",
       "      <td>2.026379</td>\n",
       "      <td>-0.237219</td>\n",
       "      <td>-0.226298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.461907</td>\n",
       "      <td>-1.733201</td>\n",
       "      <td>0.705348</td>\n",
       "      <td>-0.027248</td>\n",
       "      <td>-0.751404</td>\n",
       "      <td>-0.194335</td>\n",
       "      <td>0.415558</td>\n",
       "      <td>0.461429</td>\n",
       "      <td>0.403048</td>\n",
       "      <td>-1.409372</td>\n",
       "      <td>...</td>\n",
       "      <td>1.864714</td>\n",
       "      <td>0.429058</td>\n",
       "      <td>-0.520817</td>\n",
       "      <td>2.025422</td>\n",
       "      <td>0.676446</td>\n",
       "      <td>0.019311</td>\n",
       "      <td>1.577217</td>\n",
       "      <td>-0.755467</td>\n",
       "      <td>-1.029430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.720659</td>\n",
       "      <td>0.921458</td>\n",
       "      <td>0.191638</td>\n",
       "      <td>0.540317</td>\n",
       "      <td>-0.333272</td>\n",
       "      <td>-0.533410</td>\n",
       "      <td>0.368140</td>\n",
       "      <td>0.395090</td>\n",
       "      <td>-0.672139</td>\n",
       "      <td>0.292162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049651</td>\n",
       "      <td>0.125696</td>\n",
       "      <td>0.549344</td>\n",
       "      <td>-0.188079</td>\n",
       "      <td>0.898622</td>\n",
       "      <td>-0.414465</td>\n",
       "      <td>-0.857327</td>\n",
       "      <td>0.065929</td>\n",
       "      <td>-0.511850</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.131203</td>\n",
       "      <td>-0.224824</td>\n",
       "      <td>-1.203698</td>\n",
       "      <td>-0.599739</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>-1.105548</td>\n",
       "      <td>1.362418</td>\n",
       "      <td>-0.622372</td>\n",
       "      <td>-1.085267</td>\n",
       "      <td>0.894765</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.219154</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>1.373663</td>\n",
       "      <td>-0.036971</td>\n",
       "      <td>0.129301</td>\n",
       "      <td>-2.831946</td>\n",
       "      <td>1.555181</td>\n",
       "      <td>1.248615</td>\n",
       "      <td>1.110322</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0 -0.902180  1.442462  0.242076  0.682170 -0.545636  1.897453 -3.087657   \n",
       "1  1.027442 -0.328926 -0.795394 -0.395393  0.029429 -0.432294  0.005620   \n",
       "2 -1.461907 -1.733201  0.705348 -0.027248 -0.751404 -0.194335  0.415558   \n",
       "3 -0.720659  0.921458  0.191638  0.540317 -0.333272 -0.533410  0.368140   \n",
       "4 -0.131203 -0.224824 -1.203698 -0.599739  0.094078 -1.105548  1.362418   \n",
       "\n",
       "         V8        V9       V10  ...       V20       V21       V22       V23  \\\n",
       "0 -7.481774 -1.310739 -1.750813  ...  3.586292 -6.258702  1.163043  0.721013   \n",
       "1 -0.185605  1.049741 -0.240491  ... -0.110982  0.038445  0.528470  0.078108   \n",
       "2  0.461429  0.403048 -1.409372  ...  1.864714  0.429058 -0.520817  2.025422   \n",
       "3  0.395090 -0.672139  0.292162  ...  0.049651  0.125696  0.549344 -0.188079   \n",
       "4 -0.622372 -1.085267  0.894765  ... -1.219154 -0.017103  1.373663 -0.036971   \n",
       "\n",
       "        V24       V25       V26       V27       V28  Class  \n",
       "0 -0.838813  1.973207 -1.295843 -0.047097  0.941755      0  \n",
       "1  0.993348  0.194594  2.026379 -0.237219 -0.226298      0  \n",
       "2  0.676446  0.019311  1.577217 -0.755467 -1.029430      0  \n",
       "3  0.898622 -0.414465 -0.857327  0.065929 -0.511850      0  \n",
       "4  0.129301 -2.831946  1.555181  1.248615  1.110322      0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target 변수 설정 : 아래의 과정을 통해 데이터를 카테고리화 시킨다.\n",
    "target = pd.Series(credit.Class, dtype = \"category\")\n",
    "credit['Class'] = target \n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28432\n",
       "1      246\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    본격적으로 logistic 모델에 적합시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit.drop([\"Class\"],axis=1)\n",
    "y = credit[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21508, 28) (7170, 28) (21508,) (7170,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression \n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    만든 모델을 바탕으로 아래의 과정을 통해 y값을 예측하고 분류될 확률을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class 예측\n",
    "y_pred = classifier.predict(X_test) \n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99162657e-01, 8.37342733e-04],\n",
       "       [9.99687212e-01, 3.12787618e-04],\n",
       "       [9.79470309e-01, 2.05296911e-02],\n",
       "       ...,\n",
       "       [9.99915594e-01, 8.44058313e-05],\n",
       "       [9.96014554e-01, 3.98544568e-03],\n",
       "       [9.99193219e-01, 8.06781183e-04]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [0으로 분류될 확률, 1로 분류될 확률]\n",
    "classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Metrics Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) sklearn 패키지를 이용한 성능 평가지표 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(https://datascienceschool.net/view-notebook/731e0d2ef52c41c686ba53dcaf346f32/) 해당 사이트 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997907949790795"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean accuracy \n",
    "classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.845360824742268"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 score\n",
    "f1_score(y_pred, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7125\n",
      "           1       0.79      0.91      0.85        45\n",
      "\n",
      "    accuracy                           1.00      7170\n",
      "   macro avg       0.89      0.95      0.92      7170\n",
      "weighted avg       1.00      1.00      1.00      7170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    sklearn을 통해 성능 평가지표를 확인할 수 있다. 평균 정확도는 거의 1에 가까운 값이 나올 정도로 매우 높게 파악된다. f1 score 역시 굉장히 높게 나왔다. 또한 함수를 사용해 precision과 recall 역시 높게 나와서 모델 성능은 굉장히 높은 것으로 판단할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) confusion matrix를 이용한 성능 평가지표 계산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7114, 4, 11, 41)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7114,    4],\n",
       "       [  11,   41]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.997907949790795\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn)/(tp+fn+fp+tn)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (tp)/(tp+fp)\n",
    "recall = (tp)/(tp+fn)\n",
    "specificity = (tn)/(fp+tn)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.9111111111111111\n",
      "recall:  0.7884615384615384\n",
      "specificity:  0.9994380443944928\n",
      "f1_score:  0.845360824742268\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"specificity: \", specificity)\n",
    "print(\"f1_score: \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    sklearn과는 약간의 차이가 존재하지만 그럼에도 불구하고 전반적인 지표들은 굉장히 높다. 이를 바탕으로 성능을 파악해봤을 때, 모델의 성능을 높은 것으로 판단할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) cut-off value 찾아보기 \n",
    "* fpr = fall-out = 1-specificity\n",
    "* tpr = sensitivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    아래의 코드를 돌리면 cutoff value와 roc curve를 그릴 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test,classifier.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fpr, tpr, 'o-', label=\"Logistic Regression\") \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot([1-specificity], [recall], 'ro', ms=10) # 현재 cutoff value 값 \n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc curve 아래의 면적 \n",
    "auc = metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    실제로 위의 코드를 돌리면 위와 같은 그래프를 얻을 수 있다. 동시에 auc 면적도 확인할 수 있다. auc의 값은 1에 가까우며 모델의 성능이 좋다고 판단할 수 있다. 하지만 현재의 cutoff value는 optimal하지 않은 것을 파악할 수 있다.\n",
    "    \n",
    "    그 이유는 y의 값이 균형잡혀 있지 않기 때문이다. 위의 데이터는 사기가 일어난 경우를 1, 그렇지 않은 경우를 0으로 잡고 있다. 사기라고 하는 것이 흔히 우리의 일상생활에서 빈번하게 일어나는 일이 아니기 때문에 y에서 1의 비중은 0에 비해서 지극히 낮을 수 밖에 없다. 따라서 로지스틱 함수로 부터 구한 성공확률은 기존에 설정한 cutoff보다 대부분 낮을 수 밖에서 없다. 따라서 위와 같이 성능이 매우 뛰어남에도 불구하고 cutoff value는 optimal하지 않는 상황이 발생하게 된 것이다.\n",
    "    \n",
    "    이를 해결하기 위해선 cutoff 값을 낮춰 새로운 cutoff value로 모델을 새로 예측해야한다. 아래에 그 과정이 나열돼 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 새로운 cutoff value로 모델 예측하기 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    보통 최적의 cutoff value는 접선의 기울기가 1인 지점에 설정하곤 한다. 따라서 기울기가 1인 y = x + k 인 접선을 바탕으로 곡선과 접하는 지점을 찾으면 된다.  \n",
    "    \n",
    "    즉, (sensitivity)-(1-specificity) = k 일 때, 가장 큰 k 값을 찾으면 된다. 그 k값을 바탕으로 새로운 cutoff value를 찾고 이를 기준으로 다시 y값들을 분류한다. 과정은 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_new = classifier.decision_function(X_test) > optimal_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6899,  219],\n",
       "       [   1,   51]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 cutoff value로 분류한 confusion matrix \n",
    "confusion_matrix(y_test, predict_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6899, 219, 1, 51)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predict_new).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9693165969316597\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp+tn)/(tp+fn+fp+tn)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = (tp)/(tp+fp)\n",
    "recall = (tp)/(tp+fn)\n",
    "specificity = (tn)/(fp+tn)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.18888888888888888\n",
      "recall:  0.9807692307692307\n",
      "specificity:  0.9692329305984827\n",
      "f1_score:  0.3167701863354037\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", precision)\n",
    "print(\"recall: \", recall)\n",
    "print(\"specificity: \", specificity)\n",
    "print(\"f1_score: \", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr, tpr, 'o-', label=\"Logistic Regression\") \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot([1-(tn / (fp+tn))], [tp / (fn+tp)], 'ro', ms=10) # 현재 cutoff value 값 \n",
    "plt.xlabel('1-Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    그래프를 보면 threshold 점이 달라진 것을 확인할 수 있다. 즉, optimal threshold에 점을 찍은 것이다. 뿐만 아니라 새로운 예측값을 바탕으로 구한 confusion_matrix도 달라진 것을 확인할 수 있다. 이를 바탕으로 모델 성능 지표 역시 달라진 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q. cutoff value를 바꿔서 나온 결과의 의의는 무엇일까요 ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    cutoff value를 바꿨을 때, 눈에 띄게 결과들이 바뀌었다. 우선 그래프에서 보면 기존의 cutoff는 optimal이 아니었으나 바뀐 그래프에서는 optimal로 위치가 변경됐음을 알 수 있다. 또한 confusion_matrix의 수가 많이 바뀌었음을 알 수 있다. tn같은 경우 그 값이 많이 떨어졌고, fp 같은 경우 그 값이 많이 올랐다. 또한 tp의 값이 소폭 상승하고 fp는 소폭 하향된 것을 확인할 수 있다. \n",
    "    \n",
    "    즉, 기존의 cutoff가 자료에 비해 너무 높게 상정되어 있어서 실제 데이터와는 무관하게 y = 0이라고 예측할 확률이 컸던 것이다. 또한 정확성은 좋았지만, 이는 tp가 낮은 경우를 충분히 반영하지 못한 결과였던 것이다.\n",
    "    \n",
    "    그러나 optimal threshold를 찾아 cutoff 값을 내림으로써 confusion_matrix를 재배치 할 수 있었다. 이로써 accuracy에서 tp가 낮은 경우도 고려할 수 있게 됐다.\n",
    "    \n",
    "    또한 cutoff값을 내림으로써, Recall 값은 이전보다 올랐으나, precision 값은 이전보다 떨어진 것을 확인할 수 있었다. 이는 recall과 precision이 서로 상충되는 관계로 둘 다 동시에 올릴 수는 없다는 점을 알 수 있다.\n",
    "    \n",
    "    마지막으로 정밀도가 굉장히 하락했다는 점이 눈에 띄인다. 이 사례에서 정밀도는 사기가 발생했다고 예측한 것 중에서 실제 사기를 당한 비율을 의미한다. 이는 실제 사기를 당한 사람의 데이터의 양이 매우 적다는 점을 파악할 수 있다. 반응변수의 데이터가 매우 불균형하다는 것을 파악할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
